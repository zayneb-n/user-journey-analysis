{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fa437b-31bd-478a-b464-f1f61d86b323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  session_id subscription_type  \\\n",
      "0     1516     2980231            Annual   \n",
      "1     1516     2980248            Annual   \n",
      "2     1516     2992252            Annual   \n",
      "3     1516     3070491            Annual   \n",
      "4     1516     3709807            Annual   \n",
      "\n",
      "                                        user_journey  \n",
      "0  Homepage-Log in-Log in-Log in-Log in-Log in-Lo...  \n",
      "1  Other-Sign up-Sign up-Sign up-Sign up-Sign up-...  \n",
      "2          Log in-Log in-Log in-Log in-Log in-Log in  \n",
      "3  Homepage-Log in-Log in-Log in-Log in-Log in-Lo...  \n",
      "4  Log in-Log in-Log in-Log in-Log in-Log in-Log ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv('user_journey_raw.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871f5690-8570-4385-bc7a-45a084501163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9935, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e86f56d-b4f6-4b8d-a63d-eca63d0c2373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id              0.0\n",
      "session_id           0.0\n",
      "subscription_type    0.0\n",
      "user_journey         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().mean() * 100) #percentage of the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f997422-7537-411c-b649-77e467522f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id               int64\n",
      "session_id            int64\n",
      "subscription_type    object\n",
      "user_journey         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1e4696-7998-4829-a3ff-92571ec24667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Homepage-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Log in-Other'\n",
      " 'Other-Sign up-Sign up-Sign up-Sign up-Sign up-Log in-Log in-Log in-Log in-Log in-Log in'\n",
      " 'Log in-Log in-Log in-Log in-Log in-Log in' ...\n",
      " 'Other-Career tracks-Career tracks-Courses-Courses-Courses-Courses-Career tracks-Career tracks-Sign up-Sign up-Sign up-Sign up-Sign up-Sign up-Sign up-Sign up-Sign up'\n",
      " 'Other-Other-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon-Coupon'\n",
      " 'Homepage-Upcoming courses']\n"
     ]
    }
   ],
   "source": [
    "print(data['user_journey'].unique()) #detect inconsistent data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab5f701-a63b-4a36-961f-0fe8efe5d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_page_duplicates(data, target_column='user_journey'):\n",
    "    \"\"\"\n",
    "    Removes sequences of repeating pages in the user journey strings.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame containing the data.\n",
    "    - target_column: Column name containing user journey strings (default 'user_journey').\n",
    "    \n",
    "    Returns:\n",
    "    - A new DataFrame with cleaned-up user journey strings.\n",
    "    \"\"\"\n",
    "    # Copy the original dataframe to avoid modifying it\n",
    "    cleaned_data = data.copy()\n",
    "    \n",
    "    # Function to remove consecutive duplicates from a journey string\n",
    "    def clean_journey(journey):\n",
    "        pages = journey.split('-')  # Split into individual pages\n",
    "        cleaned_pages = [pages[0]]  # Initialize with the first page\n",
    "        for page in pages[1:]:\n",
    "            if page != cleaned_pages[-1]:  # Add only if different from the previous\n",
    "                cleaned_pages.append(page)\n",
    "        return '-'.join(cleaned_pages)  # Rejoin into a string\n",
    "    # Apply the cleaning function to the target column\n",
    "    cleaned_data[target_column] = cleaned_data[target_column].apply(clean_journey)\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fceaf7c-b834-4960-a8df-3b7eda98d4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id  session_id subscription_type           user_journey\n",
      "0        1516     2980231            Annual  Homepage-Log in-Other\n",
      "1        1516     2980248            Annual   Other-Sign up-Log in\n",
      "2        1516     2992252            Annual                 Log in\n",
      "3        1516     3070491            Annual        Homepage-Log in\n",
      "4        1516     3709807            Annual                 Log in\n",
      "...       ...         ...               ...                    ...\n",
      "9930   509095     4487613            Annual                  Other\n",
      "9931   509095     4842565            Annual                  Other\n",
      "9932   509095     4843103            Annual                  Other\n",
      "9933   509095     4845316            Annual                  Other\n",
      "9934   509096     4845427            Annual           Other-Coupon\n",
      "\n",
      "[9935 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "cleaned_data = remove_page_duplicates(data)\n",
    "\n",
    "# Output DataFrame\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88db6721-428b-404d-b3d9-f96db6571738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(grouped_df, group_column='user_id', target_column='user_journey', sessions='All', count_from='last'):\n",
    "    \"\"\"\n",
    "    Groups user sessions into a single journey string for each user.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame containing the data.\n",
    "    - group_column: Column name to group by (default 'user_id').\n",
    "    - target_column: Column containing journey strings to combine (default 'user_journey').\n",
    "    - sessions: Number of sessions to group ('All' or an integer, default 'All').\n",
    "    - count_from: 'first' or 'last', where to start grouping if sessions is an integer (default 'last').\n",
    "\n",
    "    Returns:\n",
    "    - A new DataFrame with grouped journey strings.\n",
    "    \"\"\"\n",
    "    # Copy the original dataframe to avoid modification\n",
    "    grouped_df = cleaned_data.copy()\n",
    "\n",
    "    # Function to group journeys\n",
    "    def group_journeys(sub_df):\n",
    "        if sessions == 'All':\n",
    "            return '-'.join(sub_df[target_column])\n",
    "        elif count_from == 'first':\n",
    "            return '-'.join(sub_df[target_column].iloc[:sessions])\n",
    "        elif count_from == 'last':\n",
    "            return '-'.join(sub_df[target_column].iloc[-sessions:])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for 'count_from'. Choose 'first' or 'last'.\")\n",
    "\n",
    "    # Perform grouping and apply function\n",
    "    '''\n",
    "    group_keys=False: Ensures that only the target DataFrame rows are passed to the apply function, excluding the grouping keys.\n",
    "    '''\n",
    "    result = (\n",
    "        grouped_df.groupby(group_column, group_keys=False)\n",
    "        .apply(group_journeys)\n",
    "        .reset_index(name=target_column)\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f07fee5-c241-4cd1-8c5e-73d346fc437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id                                       user_journey\n",
      "0        1516  Homepage-Log in-Other-Other-Sign up-Log in-Log...\n",
      "1        3395  Other-Pricing-Sign up-Log in-Homepage-Pricing-...\n",
      "2       10107  Homepage-Homepage-Career tracks-Homepage-Caree...\n",
      "3       11145  Homepage-Log in-Homepage-Log in-Homepage-Log i...\n",
      "4       12400  Homepage-Career tracks-Sign up-Log in-Other-Ca...\n",
      "...       ...                                                ...\n",
      "1345   509060                                        Other-Other\n",
      "1346   509061                                             Coupon\n",
      "1347   509085                                             Coupon\n",
      "1348   509095                            Other-Other-Other-Other\n",
      "1349   509096                                       Other-Coupon\n",
      "\n",
      "[1350 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21693\\AppData\\Local\\Temp\\ipykernel_6700\\4269526294.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(group_journeys)\n"
     ]
    }
   ],
   "source": [
    "cleaned_grouped_df = group_by(cleaned_data)\n",
    "print(cleaned_grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf704942-62d1-4dfc-b2fd-df42b27a4d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id                                       user_journey\n",
      "0     1516  Homepage-Log in-Other-Other-Sign up-Log in-Log...\n",
      "1     3395  Other-Pricing-Sign up-Log in-Homepage-Pricing-...\n",
      "2    10107  Homepage-Homepage-Career tracks-Homepage-Caree...\n",
      "3    11145  Homepage-Log in-Homepage-Log in-Homepage-Log i...\n",
      "4    12400  Homepage-Career tracks-Sign up-Log in-Other-Ca...\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_grouped_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbb7e972-ad1d-4d7a-a8f7-cece58e87c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pages(dataframe , pages, target_column='user_journey'):\n",
    "    \"\"\"\n",
    "    Removes specified pages from the user journey strings in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame containing the data.\n",
    "    - pages: List of page strings to remove.\n",
    "    - target_column: Column containing user journey strings (default 'user_journey').\n",
    "    \n",
    "    Returns:\n",
    "    - A new DataFrame with the specified pages removed.\n",
    "    \"\"\"\n",
    "    # Copy the original dataframe to avoid modifying it\n",
    "    dataframe = cleaned_grouped_df.copy()\n",
    "    \n",
    "    # Function to remove pages from a journey string\n",
    "    def clean_journey(journey):\n",
    "        journey_pages = journey.split('-')  # Split into individual pages\n",
    "        filtered_pages = [page for page in journey_pages if page not in pages]  # Filter out unwanted pages\n",
    "        return '-'.join(filtered_pages)  # Rejoin into a string\n",
    "    \n",
    "    # Apply the cleaning function to the target column\n",
    "    dataframe[target_column] = dataframe[target_column].apply(clean_journey)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49f55a7b-29bf-4bce-b645-216e2e110d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id                                       user_journey\n",
      "0        1516  Homepage-Other-Other-Sign up-Homepage-Checkout...\n",
      "1        3395  Other-Pricing-Sign up-Homepage-Pricing-Pricing...\n",
      "2       10107  Homepage-Homepage-Career tracks-Homepage-Caree...\n",
      "3       11145  Homepage-Homepage-Homepage-Homepage-Homepage-H...\n",
      "4       12400  Homepage-Career tracks-Sign up-Other-Career tr...\n",
      "...       ...                                                ...\n",
      "1345   509060                                        Other-Other\n",
      "1346   509061                                             Coupon\n",
      "1347   509085                                             Coupon\n",
      "1348   509095                            Other-Other-Other-Other\n",
      "1349   509096                                       Other-Coupon\n",
      "\n",
      "[1350 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the pages to remove\n",
    "pages_to_remove = ['Log in', 'Log out']\n",
    "\n",
    "# Apply the remove_pages function\n",
    "processed_dataframe = remove_pages(cleaned_grouped_df, pages_to_remove)\n",
    "\n",
    "# Display the result\n",
    "print(processed_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b7d48d9-cfee-4fde-811a-ae1f3f5aa0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id                                       user_journey\n",
      "0        1516  Homepage-Other-Sign up-Homepage-Checkout-Coupo...\n",
      "1        3395    Other-Pricing-Sign up-Homepage-Pricing-Checkout\n",
      "2       10107  Homepage-Career tracks-Homepage-Career tracks-...\n",
      "3       11145                                  Homepage-Checkout\n",
      "4       12400  Homepage-Career tracks-Sign up-Other-Career tr...\n",
      "...       ...                                                ...\n",
      "1345   509060                                              Other\n",
      "1346   509061                                             Coupon\n",
      "1347   509085                                             Coupon\n",
      "1348   509095                                              Other\n",
      "1349   509096                                       Other-Coupon\n",
      "\n",
      "[1350 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "final_data = remove_page_duplicates(processed_dataframe)\n",
    "\n",
    "# Output DataFrame\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6a85e15-7a24-4a81-97a5-62a8ea27a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  session_id subscription_type  \\\n",
      "0     1516     2980231            Annual   \n",
      "1     1516     2980248            Annual   \n",
      "2     1516     2992252            Annual   \n",
      "3     1516     3070491            Annual   \n",
      "4     1516     3709807            Annual   \n",
      "\n",
      "                                        user_journey  \n",
      "0  Homepage-Log in-Log in-Log in-Log in-Log in-Lo...  \n",
      "1  Other-Sign up-Sign up-Sign up-Sign up-Sign up-...  \n",
      "2          Log in-Log in-Log in-Log in-Log in-Log in  \n",
      "3  Homepage-Log in-Log in-Log in-Log in-Log in-Lo...  \n",
      "4  Log in-Log in-Log in-Log in-Log in-Log in-Log ...  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "022346ca-2d92-4617-acd5-3b9b4f14d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.merge(\n",
    "    final_data,  # The processed DataFrame\n",
    "    data[['user_id', 'subscription_type']],  # Selecting only user_id and subscription_type from the original DataFrame\n",
    "    on='user_id',  # Merge on the user_id column\n",
    "    how='left'  # Use 'left' join to preserve all rows in final_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d4d3244-c909-4c4e-90d8-aef9eebcad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id                                       user_journey  \\\n",
      "0     1516  Homepage-Other-Sign up-Homepage-Checkout-Coupo...   \n",
      "1     1516  Homepage-Other-Sign up-Homepage-Checkout-Coupo...   \n",
      "2     1516  Homepage-Other-Sign up-Homepage-Checkout-Coupo...   \n",
      "3     1516  Homepage-Other-Sign up-Homepage-Checkout-Coupo...   \n",
      "4     1516  Homepage-Other-Sign up-Homepage-Checkout-Coupo...   \n",
      "\n",
      "  subscription_type  \n",
      "0            Annual  \n",
      "1            Annual  \n",
      "2            Annual  \n",
      "3            Annual  \n",
      "4            Annual  \n"
     ]
    }
   ],
   "source": [
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a28502a6-292f-402d-ab36-a989ebf4d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final_data to a CSV file\n",
    "final_data.to_csv('final_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace7e53-0648-44e4-a812-0c46a7d5acbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
